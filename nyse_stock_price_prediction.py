# -*- coding: utf-8 -*-
"""NYSE - Stock Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1meuZMpFvYj4GT3630-cDPggQI-VhWbpX

#New York Stock Exchange
##S&P 500 companies historical prices with fundamental data

- ***Source*** - **https://www.kaggle.com/dgawlik/nyse**

###Context :

- **This dataset is a playground for fundamental and technical analysis. It is said that 30% of traffic on stocks is already generated by machines, can trading be fully automated? If not, there is still a lot to learn from historical data.**

###Content
**Dataset consists of following files:**

- prices.csv: raw, as-is daily prices. Most of data spans from 2010 to the end 2016, for companies new on stock market date range is shorter. There have been approx. 140 stock splits in that time, this set doesn't account for that.

- prices-split-adjusted.csv: same as prices, but there have been added adjustments for splits.

- securities.csv: general description of each company with division on sectors

- fundamentals.csv: metrics extracted from annual SEC 10K fillings (2012-2016), should be enough to derive most of popular fundamental indicators.
Acknowledgements
Prices were fetched from Yahoo Finance, fundamentals are from Nasdaq Financials, extended by some fields from EDGAR SEC databases.**

###Inspiration

- **Here is couple of things one could try out with this data:**

  - One day ahead prediction: Rolling Linear Regression, ARIMA, Neural Networks, LSTM
  - Momentum/Mean-Reversion Strategies
  - Security clustering, portfolio construction/hedging
  
**Which company has biggest chance of being bankrupt? Which one is undervalued (how prices behaved afterwards), what is Return on Investment?**
"""

#Loading required Packages

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""#Read Data"""

df = pd.read_csv('prices-split-adjusted.csv', header=0)
df.head()

#Total number of Companies

df['symbol'].value_counts().index

"""- **There are total 501 Companies listed in our Data.**
- **Further, we need to choose one of the company for Analysis / Prediction. E.g: "GOOG" (Google / Alphabet)**
"""

#Lets choose one of the company

google = df[df['symbol'] == 'GOOG']
google.tail()

#Average Closing

avg_closing = google['close'].mean()

sns.set_context('poster')
plt.plot(google.close, 'black')
plt.title('Google Closing Stock Price Trend')
plt.axhline(avg_closing, color='b')
plt.annotate('Average',xy=(0,avg_closing), arrowprops=dict(facecolor='r', shrink=0.1))

google['date'] = pd.to_datetime(google['date'])
google.set_index(['date'], inplace=True)

"""#Computing 10-Days SMA / Simple Moving Average (Rolling Mean)

- **The moving average (MA) is a simple technical analysis tool that smooths out price data by creating a constantly updated average price. The average is taken over a specific period of time, like 10 days, 20 minutes, 30 weeks or any time period the trader chooses.**

- **Why Use a Moving Average ?** - 
  - **A moving average helps cut down the amount of "noise" on a price chart. Look at the direction of the moving average to get a basic idea of which way the price is moving. If it is angled up, the price is moving up (or was recently) overall; angled down, and the price is moving down overall; moving sideways, and the price is likely in a range.**

  - **Initial SMA: 10-period sum / 10**
"""

mov_avg_close = pd.rolling_mean(google['close'], 10)
mov_avg_vol = pd.rolling_mean(google['volume'], 10)
mov_avg = pd.concat([mov_avg_close, mov_avg_vol], axis=1)
mov_avg.head(20)

mov_avg.plot(secondary_y=['volume'])
plt.title('10-Day SMA - Price and Volume (Right)')

"""- **It's evident from the above Rolling Average Visualization that as Stock Price is rising over the period of Time, Volume is decreasing.**

- **We can say that Google's Stock Price is Inveresely Proportional its Stock Volume.**

### How volume and price moves reveal the market's trend ?

- **It is important to look at the relationship between volume and price.  A price move, up or down, that is on higher volume is more significant.  Therefore, an analysis of price and volume allows the investor to better interpret the trends in price and any changes thereto.  In other words, volume gives an indication of the strength (momentum) of a move in price.**

- **Current trading volume and average trading volume should be compared.  Average trading volume typically decreases when a stock is in a downtrend, because investors view negatively a stock declining in price.  An increasing price is typically coupled with increased volume, but the price can decrease without an increase in volume if investors lose interest in the issue.  On the other hand, a declining stock price may be coupled with higher volume when, for example, negative news comes out about the company.**

  - ![alt text](https://anandabhisheksingh.me/wp-content/uploads/2018/07/volume_price_relation.jpg)

#Data Preparation
"""

from sklearn.preprocessing import StandardScaler , MinMaxScaler, Normalizer

#Forecasting for next 30 days
days = 30

#Normalizing the Data
normalizer = StandardScaler()

#Dataframe shifts index by desired number of periods
target = google['close'].shift(-days)

X = google[['close']]

X = normalizer.fit_transform(X)

X = X[:-days]

X_pred = X[-days:]

target.dropna(inplace=True)

Y = target.values

X.shape, Y.shape

"""#Implementing Estimator - Linear Regression"""

from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error

xtrain, xtest, ytrain, ytest = train_test_split(X, Y, random_state=128, test_size=0.3)

est = LinearRegression(fit_intercept=True)
est.fit(xtrain, ytrain)

print ('Training Score : ' ,est.score(xtrain, ytrain), '\n')

print ('Cross Validation Score : ', cross_val_score(est, xtrain, ytrain, cv=5).mean())

"""- **"estimator.score"** - Returns the coefficient of determination **R^2** of the prediction.

- **"cross_val_score"** - Evaluates the estimator's performance to get a impression if our Model is overfitting or underfitting

- Our Estimator performance is **0.9570** and Cross Validation Score is **0.9569** which tells us that our model is a good-fit.

#Null RMSE

- **Null RMSE** is the **RMSE** that could be achieved by always predicting the mean response value. It is a **benchmark** against which you may want to measure your regression model.
"""

#null rmse
null_rmse = np.zeros_like(ytest, dtype='float')
null_rmse.fill(ytest.mean())
print ('Null RMSE : ',np.sqrt(mean_squared_error(null_rmse, ytest)))

"""#Forecasting

- Set that will contain the forecasted data
"""

forecast = est.predict(X_pred)
forecast

"""#Evaluation Metrics - RMSE

- **Root Mean Squared Error** (RMSE) is the square root of the mean of the squared errors

  - 

$$\sqrt{\frac 1n\sum_{i=1}^n(y_i-\hat{y}_i)^2}$$
"""

print ('RMSE : ',np.sqrt(mean_squared_error(est.predict(xtest), ytest)))

"""#  Adding the predicted values to dateframe by creating Time Series"""

last_date = target.index[-1]
last_date

trange = pd.date_range(last_date, periods=days+1, freq='D')[1:]
trange

#30 days of Forecasted values
forecasted_df = pd.DataFrame(forecast, index=trange, columns=['Forecast'])
forecasted_df

plt.figure(figsize=(20,8))
plt.plot(forecasted_df.index, forecasted_df['Forecast'], 'indigo', marker='o')
plt.xticks(rotation='vertical')
plt.title('Forecasted Values')

"""#What's Next ?

- **Hyper-Parameter Tuning can boost the Scores.**

- **One can also approach with Ensemble / Bagging techniques.**
"""